{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9720dca0",
   "metadata": {},
   "source": [
    "# Statistical Learning Theory\n",
    "\n",
    "\n",
    "## Exercise 1.2\n",
    "\n",
    "Suppose that we use a perceptron to detect spam messages. Let's say that each email message is represented by the frequency of occurrence of keywords, and the output is $+1$ if the message is considered spam.\n",
    "\n",
    "(a) Can you think of some keywords that will end up with a large positive weight in the perceptron?\n",
    "\n",
    "(b) How about keywords that will get a negative weight?\n",
    "\n",
    "(c) What parameter in the perceptron directly affects how many borderline messages end up being classified as spam?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73410f",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "(a) Some keywords that i think that may represent a large positive weight are: \"free\", \"offer\", \"won\", \"easy\", \"gift\", \"sorprise\", \"click here\", \"game\", among others words.\n",
    "\n",
    "(b) Thinking about the the words that may represent a negative weight are the proper name of the receptor, \"sincerelly\", \"document\", \"information\", among other.\n",
    "\n",
    "(c) The bias value $b$,  also known as the threshold of the model. This parameter directly affects how many borderline messages end up being classified as spam. The bias allows to set a threshold that helps to classify emails as spam or not, from this parameter it can be deduced how flexible the model is or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34daf27",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "The weight update rule in (1.3) has the nice interpretation that it moves in the direction of classifying $\\mathbf{x}(t)$ correctly.\n",
    "\n",
    "(a) Show that $y(t) \\mathbf{w}^{\\mathrm{T}}(t) \\mathbf{x}(t)<0$. [Hint: $\\mathbf{x}(t)$ is misclassified by $\\mathbf{w}(t)$.]\n",
    "\n",
    "(b) Show that $y(t) \\mathbf{w}^{\\mathrm{T}}(t+1) \\mathbf{x}(t)>y(t) \\mathbf{w}^{\\mathrm{T}}(t) \\mathbf{x}(t)$. [Hint: Use (1.3).]\n",
    "\n",
    "(c) As far as classifying $\\mathbf{x}(t)$ is concerned, argue that the move from $\\mathbf{w}(t)$ to $\\mathbf{w}(t+1)$ is a move 'in the right direction'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02e5d9",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "(a) Lets consider $t$ be an iteration of the perceptron algorithm in which $x(t)$ y misclassified, it means that $sing(w(t)^Tx(t) \\neq y(t)$. Since $y(t) \\in \\{-1, +1\\}$ we have that $y(t)w(t)^Tx(t) < 0$.\n",
    "\n",
    "(b) We know that the update weight in the $t+1$ iteration is\n",
    "\n",
    "\\begin{equation*}\n",
    "w(t+1) = w(t) + y(t)x(t)\n",
    "\\end{equation*}\n",
    "\n",
    "and using the part (a), we have\n",
    "\n",
    "$$\\begin{align*}\n",
    "y(t)w(t+1)^Tx(t)&=y(t)(w(t)^Tx(t)+y(t)x(t)^Tx(t)), \\\\\n",
    "&=y(t)w(t)^Tx(t)+ y(t)^2x(t)^Tx(t),\\\\\n",
    "&=y(t)w(t)^Tx(t)+ x(t)^Tx(t),\\\\\n",
    "&>y(t)w(t)^Tx(t).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "what we were looking for.\n",
    "\n",
    "(c) It is interesting to ask ourselves how it is possible that with each iteration $w(t)$ gets closer to the correct solution. Althought the update rule only considers one training example at a time and that could damage the classification of other previously classified examples that are not in the current iteration, it is possible to guarantee the arrival of the final correct solution. According to part (b) we have that $y(t)w(t)^Tx(t) < y(t)w(t+1)^Tx(t)$, which in short means that if $y(t)w(t)^Tx(t)<0$ with the current iteration, $sign(w(t+1)^Tx(t)) = y(t)$, so each training example is going to be well classified, which implies that $w(t+1)$ is getting closer to the correct solution, that is, it moves in the right direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bea54",
   "metadata": {},
   "source": [
    "## Exercise 1.10\n",
    "\n",
    "Here is an experiment that illustrates the difference between a single bin and multiple bins. Run a computer simulation for flipping 1,000 fair coins. Flip each coin independently 10 times. Let's focus on 3 coins as follows: $c_{1}$ is the first coin flipped; $c_{\\text {rand }}$ is a coin you choose at random; $c_{\\min }$ is the coin that had the minimum frequency of heads (pick the earlier one in case of a tie). Let $\\nu_{1}, \\nu_{\\text {rand }}$ and $\\nu_{\\min }$ be the fraction of heads you obtain for the respective three coins.\n",
    "\n",
    "(a) What is $\\mu$ for the three coins selected?\n",
    "\n",
    "(b) Repeat this entire experiment a large number of times (e.g., 100, 000 runs of the entire experiment) to get several instances of $\\nu_{1}$, $\\nu_{\\text {rand }}$ and $\\nu_{\\min }$ and plot the histograms of the distributions of $\\nu_{1}, \\nu_{\\text {rand }}$ and $\\nu_{\\min }$. Notice that which coins end up being $c_{\\text {rand }}$ and $c_{\\min }$ may differ from one run to another.\n",
    "\n",
    "(c) Using (b), plot estimates for $\\mathbb{P}[|\\nu-\\mu|>\\epsilon]$ as a function of $\\epsilon$, together with the Hoeffding bound $2 e^{-2 \\epsilon^{2} N}$ (on the same graph).\n",
    "\n",
    "(d) Which coins obey the Hoeffding bound, and which ones do not? Explain why.\n",
    "\n",
    "(e) Relate part (d) to the multiple bins in Figure 1.10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1763e22",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "We will implement the following code to do a simulation in which there are 1000 fair coins and 10 independent flips are performed. First let's define the functions we're going to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bf963a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_once (generic function with 2 methods)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load packages\n",
    "\n",
    "using Random\n",
    "using StableRNGs\n",
    "using StatsBase\n",
    "using Ranges\n",
    "using Printf\n",
    "\n",
    "# Flip all coins once, return their head/tail status\n",
    "\n",
    "\n",
    "function flip_coins(total_coins)\n",
    "    ht = zeros(total_coins, 1); #head : 1, tail : 0\n",
    "    prob = rand(MersenneTwister(0), total_coins);\n",
    "    for i = 1:size(prob,1)\n",
    "        if prob[i] > 0.5\n",
    "            ht[i] = 1;\n",
    "        else\n",
    "            ht[i] = 0;\n",
    "        end\n",
    "    end\n",
    "    return(ht)\n",
    "end \n",
    "\n",
    "\n",
    "function run_once(total_coins, total_flips)\n",
    "    v_1, v_rand, v_min = nothing, nothing, nothing;\n",
    "    c_rand = rand(StableRNG(10), 1:total_coins, 1);\n",
    "    ht_sum = zeros(total_coins, 1); # store the sum of heads in total_flips\n",
    "    \n",
    "    for flip in range(total_flips)\n",
    "        ht_sum = ht_sum + flip_coins(total_coins);\n",
    "    end\n",
    "    ht_freq = (1/total_flips) * ht_sum;\n",
    "    v_1 = ht_freq[1];\n",
    "    v_rand = ht_freq[c_rand];\n",
    "    \n",
    "    \n",
    "    #Index of the coin with the minimin frequency\n",
    "    minval, posind = findmin(ht_sum);\n",
    "    c_min = posind[1];\n",
    "    \n",
    "\n",
    "    v_min = ht_freq[c_min];\n",
    "    \n",
    "    println(\"Frequency of first coin:\",v_1)\n",
    "    println(\"Frequency of a random coin:\", v_rand)\n",
    "    println(\"Frequency of the coin with minimum frequency:\", v_min)\n",
    " \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "336d2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of first coin:1.0\n",
      "Frequency of a random coin:[0.0]\n",
      "Frequency of the coin with minimum frequency:0.0\n"
     ]
    }
   ],
   "source": [
    "# (a)\n",
    "\n",
    "total_coins = 1000;\n",
    "total_flips = 10;\n",
    "run_once(total_coins, total_flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d0d17dd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: line break in \":\" expression",
     "output_type": "error",
     "traceback": [
      "syntax: line break in \":\" expression",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[129]:8",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "\n",
    "total_coins = 1000;\n",
    "total_flips = 10;\n",
    "total_runs = 1000000;\n",
    "v_1_s, v_rand_s, v_min_s = [],[],[]\n",
    "for run in range(total_runs):\n",
    "    v_1, v_rand, v_min = run_once(total_coins, total_flips)\n",
    "    push!(v_1_s, v_1)\n",
    "    push!(v_rand_s, v_rand)\n",
    "    push!(v_min_s, v_min)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, sharey=True, tight_layout=True)\n",
    "n_bins = 10\n",
    "axs[0].histogram(v1s, bins=n_bins)\n",
    "axs[1].histogram(vrands,bins=n_bins)\n",
    "axs[2].histogram(vmins,bins=n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f33bbf",
   "metadata": {},
   "source": [
    "## Exercise 1.11\n",
    "We are given a datatset $\\mathcal{D}$ of $25$ training examples from an unknown target function $f : \\mathcal{X} \\longrightarrow \\mathcal{Y}$ where $\\mathcal{X} = \\mathbb{R}$ and $\\mathcal{Y} = \\{-1, +1\\}$. To learn $f$ we use a simple hypothesis set $\\mathcal{H} = \\{h_1, h_2\\}$ where $h_1$ is the constant $+1$ function and $h_2$ is the constant $-1$.\n",
    "\n",
    "We consider two learning algorithms, $S$ (smart) and $C$ (crazy). $S$ chooses the hypothesis that agrees the most with $\\mathcal{D}$ and $C$ chooses the other hypothesis deliberately. Let us see how these algorithms perform out of sample from the deterministic and probabilistic points of view. Assume in the probabilistic view that there is a probability distribution on $\\mathcal{X}$, and let $\\mathbb{P}[f(x) = +1] = p$.\n",
    "\n",
    "(a) Can $S$ produce a hypothesis that is guaranteed to perform better than random on any point outside $\\mathcal{D}$?\n",
    "\n",
    "(b) Assume for the rest of the exercise that all the examples in $\\mathcal{D}$ have $y_n = +1$. Is it possible that the hypothesis that $C$ produces turns out to be better than the hypothesis that $S$ produces?\n",
    "\n",
    "(c) If $p = 0.9$, what is the probability that $S$ will produce a better hypothesis than $C$?\n",
    "\n",
    "(d)Is there any value of $p$ for which it is more likely than not that $C$ will produce a better hypothesis than $S$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed072e9e",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "(a) No, S can't produce a hypothesis that is guaranteed to perform better than random on any point outside. If the target function $f$ has a $25$ $+1$ on $\\mathcal{D}$ and $-1$ on all other points in $\\mathcal{X}$, the $S$ will choose $h_1$ from the hypothesis set $\\mathcal{H}$, but this fuction would't coincide with the target function $f$. On the other hand, the function that randomly chooses $+1$ or $-1$ could match $f$ out of the set $\\mathcal{D}$ with a probability of $\\frac{1}{2}$ which is more than the performance of the algorithm $S$ can offer.\n",
    "\n",
    "(b) Yes, it's posible that $C$ produces better hypothesis than $S$ produces. As we can see in the part (a), $C$ matches $f$ everwhere outside $\\mathcal{D}$ much better than $S$ which has probability $0$ of matching outside $\\mathcal{D}\n",
    "\n",
    "(c) If every point in $\\mathcal{D}$ has $+1$, then $S$ could choose $h_1$ as hypothesis. So, outside $\\mathcal{D}$ $h_1$ will have $90 \\%$ of chance to match with $f$, while $h_2$ will have only $10 \\%$ of chances. In this way, if $p = 0.9$, $S$ always produces better hypothesis than $C$.\n",
    "\n",
    "(d) As could be seen in the previous parts, if $p<0.5$, $C$ provides better hypothesis than $S$. Since $C$ always produce $h_2$ which will match $f$ better than $h_1$ if $p < 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10418b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
